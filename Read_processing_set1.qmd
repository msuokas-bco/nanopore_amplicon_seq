---
title: "Processing nanopore reads"
author: "Marko Suokas"
format: pdf
pdf-engine: lualatex
editor: visual
mainfont: Aptos
monofont: PT Mono
always_allow_html: yes
header-includes:
   \usepackage[dvipsnames]{xcolor}
   \definecolor{teal}{rgb}{0.0, 0.5, 0.5}
   \definecolor{ivory}{rgb}{1.0, 1.0, 0.94}
---

```{r, include=F}
# This will allow to use different font sizes inside code chunks
# Won't be included in the report
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

#### Preprocess reads

Dorado doesn't support demultiplexing of dual indexes on both 5' and 3' ends. Additionally, in ligated libraries reads can be either orientation. Our approach to demultiplex reads is using cutadapt. Index pairs are searched using linked adapters approach in forward and reverse orientation, then scripts are used to reverse complement reverse reads. Finally reads are merged

Please note that autocorrect often change double dashes in command examples.

Extracting forward reads to fastq file can be performed with following command

*cutadapt -e 0 -O 12 -g file:\~/scripts/barcodes.fasta --trimmed-only -m 1200 -o "fdemuxed/{name}.fastq.gz reads.fastq.gz*

Command will extract barcodes defined in barcodes.fasta file and output matches into individual files in fdemuxed subdirectory. Minimum length is set in example to 1200 bp.

Extracting reverse reads using reverse complemented barcodes.fasta file

*cutadapt -e 0 -O 12 -g file:\~/scripts/rev_barcodes.fasta --trimmed-only -m 1200 -o "rdemuxed/{name}.fastq.gz reads.fastq.gz*

Reads are demultiplexed into separate directory

**Tip!** O, e, m and M parameters can be used to reduce chances of misaligned matches

Next we use bash script that will process each reverse read file and reverse complement them using basic command

*seqkit seq -rp --seq-type DNA -o reverse_comp.fastq.gz reverse_out.fastq.gz*

Final step is merge. You can use simple bash script that will merge files with same base name from two separate directories using basic command

*zcat forward_out.fastq.gz reverse_comp.fastq.gz \>merged_reads.fastq.gz*

Finally, you can use cutadapt and bash scripts to trim forward and reverse PCR primers from sequence reads.

#### Import set1 to R

Load libraries

```{r, warning = F, message = F, size = "tiny"}
library(dada2);packageVersion("dada2")
library(knitr);packageVersion("knitr")
library(Biostrings);packageVersion("Biostrings")
library(tidyverse);packageVersion("tidyverse")
library(kableExtra);packageVersion("kableExtra")
library(mia);packageVersion("mia")
library(ape);packageVersion("ape")
```

\newpage

Set variables

```{r variables, warning = F, message = F, size = "tiny"}
# Path variables
path <- "data/processed/set1"
training <- "~/feature_classifiers/SILVA_SSU_r138_2019.RData"
silva <- "~/feature_classifiers/silva_nr99_v138.1_train_set.fa.gz"
species <- "~/feature_classifiers/silva_species_assignment_v138.1.fa.gz"
meta_file <- "data/set1_meta.tsv"
exportloc <- "set1/"
# Variable truncation length
truncation <- 1400
#Creates results directory
dir.create(exportloc)
#metadata file to df
metadata <- read_tsv(meta_file, show_col_types = F)
metadata <- column_to_rownames(metadata, var = "Sampleid")
```

For project, we took advantage of computing power of CSC and imported already executed data objects. R code is unaltered. Execution is controlled by eval parameter in code chunk. RDS files also save resources and time when document is edited and checked.

```{r create_lists, warning = F, message = F, size = "tiny"}
#List files inside directory
list.files(path)
# Forward fastq filenames have format: SAMPLENAME_R1_001.fastq
fnFs <- sort(list.files(path, pattern="_trimmed_all.fastq.gz", full.names = T))
# Extract sample names, assuming filenames have format: SAMPLENAME_XXX.fastq
sample.names <- sapply(strsplit(basename(fnFs), "_"), `[`, 1)
```

\newpage

Plot sequence quality profile for samples

```{r quality_profile, warning = F, message = F, size = "tiny", eval = F}
# Base quality plot
prsetI <- plotQualityProfile(fnFs[1:6])
prsetI
```

```{r, size="tiny", fig.dim = c(6.5,6.5)}
prsetI <- readRDS("rds/set1_rds/prsetI.rds")
prsetI
```

\newpage

#### Filter sequence data

Filtering reads (maxEE â‰ˆ 1 error/200 bp sequence should be good starting point for this amplicon)

```{r filterandtrim, warning=F, message=F, size="tiny", eval = F}
# Filtered files are placed in filtered subdirectory
filtFs <- file.path(path, "filtered", paste0(sample.names,
                                             "_F_filt.fastq.gz"))
# For single end data sets without phix control
names(filtFs) <- sample.names
out <- filterAndTrim(fnFs, filtFs, truncLen=truncation,
                     maxN = 0, maxEE = 7 , truncQ = 2,
                     compress = T, multithread = T, rm.phix = F)
```

```{r, size="tiny"}
out <- readRDS("rds/set1_rds/out.rds")
```

#### Learn error rates

```{r, warning = F, message = F, size = "tiny", eval = F}
# Forward read error rate
errF <- learnErrors(filtFs, multithread = T)
```

```{r, size = "tiny"}
errF <- readRDS("rds/set1_rds/errF.rds")
```

\newpage

Plot error rates

```{r plot_errors, warning = F, message = F, size = "tiny", fig.dim=c(6.5,6)}
# Plotting error rate profile for forward reads
plotErrors(errF, nominalQ = T)
```

\newpage

#### Denoise

```{r, warning = F, message = F, size = "tiny", eval = F}
dadaFs <- dada(derepFs, err = errF, multithread = T)
```

```{r, size = "tiny"}
dadaFs <- readRDS("rds/set1_rds/dadaFs.rds")
```

#### Build asv table

Dimensions tell us number of samples and variants

```{r asv_table, warning = F, message = F, size = "tiny"}
seqtab <- makeSequenceTable(dadaFs)
# Dimensions of ASV table
dim(seqtab)
```

#### Chimera removal

```{r chimeric, warning = F, message = F, size = "tiny"}
seqtab.nochim <- removeBimeraDenovo(seqtab, method = "consensus",
                                    multithread = T, verbose = F)
dim(seqtab.nochim)
```

\newpage

#### Summary

```{r summary_table, warning = F, message = F, size="tiny"}
getN <- function(x) sum(getUniques(x))
track <- cbind(out, sapply(dadaFs, getN), rowSums(seqtab.nochim),
               rowSums(seqtab.nochim != 0))
#If processing a single sample, remove the sapply calls
colnames(track) <- c("Input", "Filtered", "DenoisedF", "Nonchimeric",
                     "N:o of variants")
rownames(track) <- rownames(metadata)
kable(track, caption="Summary table")  %>%
  kable_styling(latex_options=c("striped", "HOLD_position"), font_size = 12) %>%
                row_spec(0,background = "teal", color = "ivory")
```

\newpage

#### Taxonomy assignment

Taxonomy classification against Silva 138.1 including species information.

```{r, warning = F, message = F, size = "tiny", eval = F}
taxonomy <- assignTaxonomy(seqtab.nochim, silva, multithread=3)
taxonomy <- addSpecies(taxonomy, species)
saveRDS(taxonomy, "rds/set1_rds/taxonomy.rds")
```

```{r, size = "tiny"}
taxonomy <- readRDS("rds/set1_rds/taxonomy.rds")
```

#### Create TSE object

```{r, warning = F, message = F, size = "tiny"}
#Preparing counts and variant sequences
counts <- t(seqtab.nochim)
repseq <- DNAStringSet(rownames(counts))
ASV_names <- paste0("ASV", seq(nrow(counts)))
names(repseq) <- ASV_names
rownames(counts) <- NULL
#Preparing taxonomy
rownames(taxonomy) <- NULL
#Create tse
tse_dada <- TreeSummarizedExperiment(assays = list(counts = counts),
                                     rowData = DataFrame(taxonomy),
                                     colData = DataFrame(metadata))
rownames(tse_dada) <- ASV_names
#Reference sequences
referenceSeq(tse_dada) <- repseq
#The object
tse_dada
```

#### Write results to files

Abundance table into tsv file

```{r, warning = F, message = F, size = "tiny"}
#sample names will be columns
ASVdf <- (data.frame(ASV_names,assays(tse_dada)$counts))
#write
write_tsv(ASVdf, paste0(exportloc,"asv_dada.tsv"))
```

Taxonomy table into tsv file

```{r, warning = F, message = F, size = "tiny"}
taxdf <- data.frame(ASV_names, rowData(tse_dada))
#write
write_tsv(taxdf, paste0(exportloc,"taxonomy_dada.tsv"))
```

\newpage

Variant sequences into fasta file

```{r, warning = F, message = F, size = "tiny"}
writeXStringSet(repseq, paste0(exportloc, "repseq_dada.fasta"),
                                      append = F, compress = F,
                                      format = "fasta")
```

Metadata into tsv file

```{r, warning = F, message = F, size = "tiny"}
metadf <- metadata %>% rownames_to_column(var = "Sampleid")
#write
write_tsv(metadf, paste0(exportloc,"metadata_dada.tsv"))
```

Add phylotree and save object

```{r, warning = F, message = F, size = "tiny"}
tree <- read.tree("set1/tree.nwk")
rowTree(tse_dada) <- tree
saveRDS(tse_dada, "set1/tse_dada.rds")
```

\newpage

#### Vsearch\@97%

Data has been processed in qiime, except taxonomic classification

```{r, warning = F, message = F, size = "tiny"}
#process qiime2 feature table
vs97 <- read_tsv("data/set1/feature-table97.tsv", show_col_types = F)
ASV_names <- paste0("ASV", seq(nrow(vs97)))
vs97 <- vs97[, order(colnames(vs97))]
vs97[,1] <- NULL
rownames(vs97) <- NULL
#process decipher taxonomy
taxonomy <- readRDS("rds/set1_rds/taxonomy_vsearch97.rds")
rownames(taxonomy) <- NULL
#process repseq fasta
seqs <- readDNAStringSet("data/set1/dna-sequences97.fasta")
names(seqs) <- ASV_names
#create tse
tse_vs97 <- TreeSummarizedExperiment(assays = list(counts = vs97),
                                     rowData = DataFrame(taxonomy),
                                     colData = DataFrame(metadata))
rownames(tse_vs97) <- ASV_names
#Reference sequences
referenceSeq(tse_vs97) <- seqs
#The object
tse_vs97
```

Write vsearch97 object

```{r, warning = F, message = F, size = "tiny"}
#variant_table
ASVdf <- data.frame(ASV_names, assays(tse_vs97)$counts)
write_tsv(ASVdf, "set1/asv_vs97.tsv")
#taxonomy
taxonomy <- data.frame(ASV_names, rowData(tse_vs97))
write_tsv(taxonomy, "set1/taxonomy_vs97.tsv")
#sequences
tse_vs97 %>% referenceSeq() %>% writeXStringSet("set1/repseq97.fasta",
                                      append = F, compress = F,
                                      format = "fasta")
#read and add tree
tree <- read.tree("set1/tree_vs97.nwk")
rowTree(tse_vs97) <- tree
#save rds
saveRDS(tse_vs97, "set1/tse_vs97.rds")
```

\newpage

#### Vsearch\@99%

```{r, warning = F, message = F, size = "tiny"}
#process qiime2 feature table
vs99 <- read_tsv("data/set1/feature-table99.tsv", show_col_types = F)
ASV_names <- paste0("ASV", seq(nrow(vs99)))
vs99 <- vs99[, order(colnames(vs99))]
vs99[,1] <- NULL
rownames(vs99) <- NULL
#process decipher taxonomy
taxonomy <- readRDS("rds/set1_rds/taxonomy_vsearch99.rds")
rownames(taxonomy) <- NULL
#process repseq fasta
seqs <- readDNAStringSet("data/set1/dna-sequences99.fasta")
names(seqs) <- ASV_names
#create tse
tse_vs99 <- TreeSummarizedExperiment(assays = list(counts = vs99),
                                     rowData = DataFrame(taxonomy),
                                     colData = DataFrame(metadata))
rownames(tse_vs99) <- ASV_names
#Reference sequences
referenceSeq(tse_vs99) <- seqs
#The object
tse_vs99
```

Write vsearch99 object

```{r, warning = F, message = F, size = "tiny"}
#variant_table
ASVdf <- data.frame(ASV_names, assays(tse_vs99)$counts)
write_tsv(ASVdf, "set1/asv_vs99.tsv")
#taxonomy
taxonomy <- data.frame(ASV_names, rowData(tse_vs99))
write_tsv(taxonomy, "set1/taxonomy_vs99.tsv")
#sequences
tse_vs99 %>% referenceSeq() %>% writeXStringSet("set1/repseq99.fasta",
                                      append = F, compress = F,
                                      format = "fasta")
#read and add tree
tree <- read.tree("set1/tree_vs99.nwk")
rowTree(tse_vs99) <- tree
#save rds
saveRDS(tse_vs99, "set1/tse_vs99.rds")
```

#### Observations

The low bacterial diversity in these samples may explain why denoising yields good results for long 16S rRNA sequences. The error rate plot appears flawless for this data. However, it is noteworthy that all samples contain over 150,000 unique reads.

In contrast, vsearch clustering generated a significantly higher number of variants, exceeding 900 and 9,000, respectively. Lowest number of variants (37) was observed with emu.
